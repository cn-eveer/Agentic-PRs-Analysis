{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aade586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "# ========== CONFIGURATION (EDIT ONLY THIS CELL) ==========\n",
    "# DATA_SOURCE options: 'local' (read local parquet under DATA_DIR) or 'hf' (read via HuggingFace URI)\n",
    "DATA_SOURCE = 'hf'  # set to 'hf' to read from HF dataset URIs\n",
    "\n",
    "# For local mode: set DATA_DIR to path containing parquet files or leave None to auto-detect\n",
    "DATA_DIR: Optional[Path] = None\n",
    "\n",
    "# For HF mode: base URI prefix for huggingface dataset parquet files\n",
    "HF_BASE = 'hf://datasets/hao-li/AIDev'\n",
    "\n",
    "# Hard-coded filter per request: do not change\n",
    "MIN_STARS = 500  # filter: repos with stars >= 500 (hard-coded)\n",
    "\n",
    "AGENTS = ['Claude_Code','Copilot','Cursor','Devin','OpenAI_Codex']\n",
    "\n",
    "# Bot list (taken from Untitled1.ipynb)\n",
    "BOT_LIST = [\n",
    "  'copilot-swe-agent[bot]',\n",
    "  'cursor[bot]',\n",
    "  'gemini-code-assist[bot]',\n",
    "  'copilot-pull-request-reviewer[bot]',\n",
    "  'coderabbitai[bot]',\n",
    "  'ellipsis-dev[bot]',\n",
    "  'greptile-apps[bot]',\n",
    "  'entelligence-ai-pr-reviews[bot]',\n",
    "  'Copilot',\n",
    "  'github-advanced-security[bot]',\n",
    "]\n",
    "\n",
    "# Short note: Change DATA_SOURCE / DATA_DIR / HF_BASE here to run in different environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8768b14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using HF dataset base: hf://datasets/hao-li/AIDev\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "REQUIRED_FILES = ['pull_request.parquet', 'repository.parquet']\n",
    "\n",
    "def is_dataset_dir(p: Path) -> bool:\n",
    "    return all((p / f).is_file() for f in REQUIRED_FILES)\n",
    "\n",
    "\n",
    "def find_dataset_dir(data_dir_hint: Optional[Path] = None) -> Optional[Path]:\n",
    "    candidates = []\n",
    "    if data_dir_hint:\n",
    "        candidates.append(Path(data_dir_hint))\n",
    "    candidates.extend([Path('.'), Path('..'), Path('../..')])\n",
    "\n",
    "    for cand in candidates:\n",
    "        cand = Path(cand)\n",
    "        # 1) exact match\n",
    "        if is_dataset_dir(cand):\n",
    "            return cand.resolve()\n",
    "        # 2) immediate subdirectories\n",
    "        if cand.is_dir():\n",
    "            for sub in cand.iterdir():\n",
    "                if sub.is_dir() and is_dataset_dir(sub):\n",
    "                    return sub.resolve()\n",
    "    return None\n",
    "\n",
    "# Setup depending on DATA_SOURCE\n",
    "if DATA_SOURCE == 'local':\n",
    "    BASE = find_dataset_dir(DATA_DIR)\n",
    "    if BASE is None:\n",
    "        raise FileNotFoundError(\n",
    "            \"Dataset directory could not be automatically detected.\\n\"\n",
    "            \"Set the DATA_DIR environment variable or explicitly set DATA_DIR in the top configuration cell.\\n\"\n",
    "            \"Example: DATA_DIR = Path('/path/to/dataset_dir')\"\n",
    "        )\n",
    "    REPO_ROOT = BASE.parent\n",
    "    OUT_DIR = REPO_ROOT / 'replicationPackage' / 'outputs'\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print('Dataset dir detected:', relpath_to_repo(BASE, REPO_ROOT))\n",
    "else:\n",
    "    # HF mode: no local BASE required\n",
    "    BASE = None\n",
    "    REPO_ROOT = Path('.')\n",
    "    OUT_DIR = REPO_ROOT / 'replicationPackage' / 'outputs'\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print('Using HF dataset base:', HF_BASE)\n",
    "\n",
    "# Friendly relative-path printer (avoid showing absolute paths)\n",
    "def relpath_to_repo(p: Path, repo_root: Optional[Path] = None) -> str:\n",
    "    try:\n",
    "        if repo_root is None:\n",
    "            repo_root = p\n",
    "        return Path(p).relative_to(repo_root).as_posix()\n",
    "    except Exception:\n",
    "        return Path(p).as_posix()\n",
    "\n",
    "# Unified reader (calls HF URI when requested)\n",
    "\n",
    "def read_parquet_file(name: str, columns=None):\n",
    "    import pandas as _pd\n",
    "    if DATA_SOURCE == 'hf':\n",
    "        uri = f\"{HF_BASE}/{name}\"\n",
    "        return _pd.read_parquet(uri, columns=columns)\n",
    "    else:\n",
    "        return _pd.read_parquet(BASE / name, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5970c212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repos: (2807, 2)\n",
      "prs: (33596, 7)\n",
      "comments: (39122, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load minimal columns only (fast + reproducible)\n",
    "repos = read_parquet_file('repository.parquet', columns=['id','stars'])\n",
    "prs = read_parquet_file(\n",
    "    'pull_request.parquet',\n",
    "    columns=['id','repo_id','agent','user','state','merged_at','html_url']\n",
    ")\n",
    "comments = read_parquet_file('pr_comments.parquet', columns=['pr_id','user_type'])\n",
    "\n",
    "print('repos:', repos.shape)\n",
    "print('prs:', prs.shape)\n",
    "print('comments:', comments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6e5d8e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repos with stars>=500: 1479\n",
      "selected closed agentic PRs: 11048\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Universe selection (paper-aligned): repos with stars>=500, and closed PRs\n",
    "repo_ids = set(repos.loc[repos['stars'] >= MIN_STARS, 'id'].astype(int).tolist())\n",
    "print('repos with stars>=500:', len(repo_ids))\n",
    "\n",
    "selected = prs[(prs['repo_id'].astype(int).isin(repo_ids)) & (prs['state'] == 'closed')].copy()\n",
    "selected_ids = set(selected['id'].astype(int).tolist())\n",
    "print('selected closed agentic PRs:', len(selected_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d20c1af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bot_assigned (author in BOT_LIST): 2681\n",
      "excluded (bot_assigned & no User comments): 1249\n",
      "kept: 9799\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "bot_assigned = selected[selected['user'].isin(BOT_LIST)].copy()\n",
    "print('bot_assigned (author in BOT_LIST):', len(bot_assigned))\n",
    "\n",
    "user_commented_pr_ids = set(\n",
    "    comments.loc[comments['user_type'] == 'User', 'pr_id']\n",
    "    .dropna().astype(int).unique().tolist()\n",
    ")\n",
    "\n",
    "excluded = bot_assigned[~bot_assigned['id'].astype(int).isin(user_commented_pr_ids)].copy()\n",
    "excluded_ids = set(excluded['id'].astype(int).tolist())\n",
    "\n",
    "kept_ids = selected_ids - excluded_ids\n",
    "print('excluded (bot_assigned & no User comments):', len(excluded_ids))\n",
    "print('kept:', len(kept_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ff2d42a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "agent",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "total",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "merged",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rejected",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "f94a8755-1f03-4d32-aa8e-925357ee1e78",
       "rows": [
        [
         "0",
         "Claude_Code",
         "213",
         "130",
         "83"
        ],
        [
         "1",
         "Copilot",
         "1429",
         "839",
         "590"
        ],
        [
         "2",
         "Cursor",
         "788",
         "563",
         "225"
        ],
        [
         "3",
         "Devin",
         "3380",
         "1813",
         "1567"
        ],
        [
         "4",
         "OpenAI_Codex",
         "3989",
         "2834",
         "1155"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>total</th>\n",
       "      <th>merged</th>\n",
       "      <th>rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>213</td>\n",
       "      <td>130</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Copilot</td>\n",
       "      <td>1429</td>\n",
       "      <td>839</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cursor</td>\n",
       "      <td>788</td>\n",
       "      <td>563</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Devin</td>\n",
       "      <td>3380</td>\n",
       "      <td>1813</td>\n",
       "      <td>1567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OpenAI_Codex</td>\n",
       "      <td>3989</td>\n",
       "      <td>2834</td>\n",
       "      <td>1155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          agent  total  merged  rejected\n",
       "0   Claude_Code    213     130        83\n",
       "1       Copilot   1429     839       590\n",
       "2        Cursor    788     563       225\n",
       "3         Devin   3380    1813      1567\n",
       "4  OpenAI_Codex   3989    2834      1155"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL 9799 6179 3620\n"
     ]
    }
   ],
   "source": [
    "kept = selected[~selected['id'].astype(int).isin(excluded_ids)].copy()\n",
    "kept['is_merged'] = kept['merged_at'].notna()\n",
    "\n",
    "_table = (\n",
    "    kept.groupby('agent')\n",
    "    .agg(total=('id','count'), merged=('is_merged','sum'))\n",
    "    .reset_index()\n",
    ")\n",
    "_table['rejected'] = _table['total'] - _table['merged']\n",
    "\n",
    "order = {a: i for i, a in enumerate(AGENTS)}\n",
    "table1 = _table[_table['agent'].isin(AGENTS)].copy()\n",
    "table1['__order'] = table1['agent'].map(order)\n",
    "table1 = table1.sort_values('__order').drop(columns=['__order']).reset_index(drop=True)\n",
    "\n",
    "try:\n",
    "    display(table1)\n",
    "except NameError:\n",
    "    print(table1.to_string(index=False))\n",
    "\n",
    "print('TOTAL', int(table1['total'].sum()), int(table1['merged'].sum()), int(table1['rejected'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ddeb56b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "agent",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "total",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "merged",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rejected",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "c249f9f8-a065-4452-a6dc-99ce38509e38",
       "rows": [
        [
         "0",
         "Claude_Code",
         "213",
         "130",
         "83"
        ],
        [
         "1",
         "Copilot",
         "1429",
         "839",
         "590"
        ],
        [
         "2",
         "Cursor",
         "788",
         "563",
         "225"
        ],
        [
         "3",
         "Devin",
         "3380",
         "1813",
         "1567"
        ],
        [
         "4",
         "OpenAI_Codex",
         "3989",
         "2834",
         "1155"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>total</th>\n",
       "      <th>merged</th>\n",
       "      <th>rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>213</td>\n",
       "      <td>130</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Copilot</td>\n",
       "      <td>1429</td>\n",
       "      <td>839</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cursor</td>\n",
       "      <td>788</td>\n",
       "      <td>563</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Devin</td>\n",
       "      <td>3380</td>\n",
       "      <td>1813</td>\n",
       "      <td>1567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OpenAI_Codex</td>\n",
       "      <td>3989</td>\n",
       "      <td>2834</td>\n",
       "      <td>1155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          agent  total  merged  rejected\n",
       "0   Claude_Code    213     130        83\n",
       "1       Copilot   1429     839       590\n",
       "2        Cursor    788     563       225\n",
       "3         Devin   3380    1813      1567\n",
       "4  OpenAI_Codex   3989    2834      1155"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL 9799 6179 3620\n",
      "Excluded count: 1249\n",
      "Kept count: 9799\n",
      "Sample excluded ids (first 10): [3074526770, 3074531119, 3074557301, 3074635096, 3074652778, 3074763951, 3074773765, 3074774643, 3074779290, 3074784299]\n",
      "Sample kept ids (first 10): [2756921963, 2757103560, 2757124156, 2757125491, 2757179026, 2757674020, 2757829316, 2758172742, 2758200405, 2758379503]\n"
     ]
    }
   ],
   "source": [
    "# Print results only (no file writes)\n",
    "try:\n",
    "    display(table1)\n",
    "except NameError:\n",
    "    print(table1.to_string(index=False))\n",
    "\n",
    "print('TOTAL', int(table1['total'].sum()), int(table1['merged'].sum()), int(table1['rejected'].sum()))\n",
    "print('Excluded count:', len(excluded_ids))\n",
    "print('Kept count:', len(kept_ids))\n",
    "print('Sample excluded ids (first 10):', sorted(excluded_ids)[:10])\n",
    "print('Sample kept ids (first 10):', sorted(kept_ids)[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
